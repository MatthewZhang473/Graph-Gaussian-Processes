{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The functionalities in this notebook is as follows:\n",
    "\n",
    "1. Given a graph, calculate the kernel matrix - diffusion for example\n",
    "\n",
    "2. Sample from a GP with this kernel matrix, for a given hyper parameters\n",
    "\n",
    "3. fit another GP with the same kernel  (and unknown hyperparamters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sample data from a GP on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a979ffa66042d29ee3ed8e9e026b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='Beta (σ):', max=10.0, min=0.1), Output()), _dom_clas…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from ipywidgets import FloatSlider, interactive\n",
    "\n",
    "def diffusion_kernel(adj_matrix, beta):\n",
    "    laplacian = np.diag(np.sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "    return expm(-beta * laplacian)  # Matrix exponential\n",
    "\n",
    "def plot_sampled_values(beta):\n",
    "    num_nodes = 20\n",
    "    adjacency_matrix = np.eye(num_nodes, k=1) + np.eye(num_nodes, k=-1)  # Circular adjacency matrix\n",
    "    K = diffusion_kernel(adjacency_matrix, beta)\n",
    "    L = np.linalg.cholesky(K + 1e-6 * np.eye(num_nodes))  # Cholesky decomposition\n",
    "    samples = L @ np.random.normal(size=(num_nodes, 1))  # Sample from Gaussian process\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot sampled values\n",
    "    axs[0].plot(range(num_nodes), samples.flatten(), marker='o', linestyle='-', color='b')\n",
    "    axs[0].set_title(f'Sampled Values for Each Node in Circular Graph (beta={beta:.2f})')\n",
    "    axs[0].set_xlabel('Node Number')\n",
    "    axs[0].set_ylabel('Sampled Value')\n",
    "    axs[0].set_xticks(range(num_nodes))\n",
    "    axs[0].grid()\n",
    "\n",
    "    # Plot kernel matrix as a heatmap\n",
    "    cax = axs[1].matshow(K, cmap='viridis')  # Heatmap of the kernel matrix\n",
    "    axs[1].set_title(f'Kernel Matrix Heatmap (beta={beta:.2f})')\n",
    "    plt.colorbar(cax, ax=axs[1])\n",
    "    axs[1].set_xlabel('Node Index')\n",
    "    axs[1].set_ylabel('Node Index')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider for beta\n",
    "beta_slider = FloatSlider(value=2.0, min=0.1, max=10.0, step=0.1, description='Beta (σ):')\n",
    "interactive_plot = interactive(plot_sampled_values, beta=beta_slider)\n",
    "interactive_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the sampled data in a new GP\n",
    "\n",
    "1. define a kernel compatible with GPflow, with tunable parameters\n",
    "\n",
    "2. learn the hyper-parameters by maximizing log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f1b89c9077405093d802366f4fc040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=3.0, description='Beta:', max=10.0, min=0.1),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824daf1196654a5bb08686b30c1a88bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Function to compute the diffusion kernel\n",
    "def diffusion_kernel(adj_matrix, beta):\n",
    "    laplacian = np.diag(np.sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "    return expm(-beta * laplacian)  # Matrix exponential\n",
    "\n",
    "# Parameters\n",
    "num_nodes = 50\n",
    "adjacency_matrix = np.eye(num_nodes, k=1) + np.eye(num_nodes, k=-1)  # Circular adjacency matrix\n",
    "\n",
    "# Generate noisy samples function\n",
    "def generate_noisy_samples(beta_sample):\n",
    "    K = diffusion_kernel(adjacency_matrix, beta_sample)\n",
    "    L = np.linalg.cholesky(K + 1e-6 * np.eye(num_nodes))  # Cholesky decomposition\n",
    "    true_samples = L @ np.random.normal(size=(num_nodes, 1))  # Sample from Gaussian process\n",
    "    noise = 0.1 * np.random.randn(num_nodes, 1)  # Additive noise\n",
    "    Y_noisy = true_samples + noise  # Noisy observations\n",
    "    return Y_noisy\n",
    "\n",
    "# Modified `K` function in GraphDiffusionKernel class\n",
    "class GraphDiffusionKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self, adjacency_matrix, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.adjacency_matrix = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float64)\n",
    "        self.beta = gpflow.Parameter(2.0, transform=gpflow.utilities.positive())  # Learnable hyperparameter\n",
    "\n",
    "    def K(self, X1, X2=None):\n",
    "        if X2 is None:\n",
    "            X2 = X1\n",
    "        # Compute the full diffusion kernel\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        # Select the appropriate submatrix based on X1 and X2 indices\n",
    "        indices_X1 = tf.cast(tf.reshape(X1, [-1]), dtype=tf.int32)\n",
    "        indices_X2 = tf.cast(tf.reshape(X2, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.gather(kernel_matrix, indices_X1, axis=0), indices_X2, axis=1)\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        indices_X = tf.cast(tf.reshape(X, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.linalg.diag_part(kernel_matrix), indices_X)\n",
    "\n",
    "    def diffusion_kernel(self, adj_matrix, beta):\n",
    "        laplacian = tf.linalg.diag(tf.reduce_sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "        return tf.linalg.expm(-beta * laplacian)\n",
    "\n",
    "# Function to plot the results\n",
    "def plot_results(beta_sample):\n",
    "    # Generate noisy samples\n",
    "    Y_noisy = generate_noisy_samples(beta_sample)\n",
    "\n",
    "    # Convert noisy data to TensorFlow tensor\n",
    "    X = tf.convert_to_tensor(np.arange(num_nodes, dtype=np.float64).reshape(-1, 1))  # Input features (nodes)\n",
    "    Y = tf.convert_to_tensor(Y_noisy, dtype=tf.float64)  # Noisy sampled data\n",
    "\n",
    "    # Create an instance of the kernel\n",
    "    graph_kernel = GraphDiffusionKernel(adjacency_matrix)\n",
    "\n",
    "    # GPflow model\n",
    "    model = gpflow.models.GPR(data=(X, Y), kernel=graph_kernel, mean_function=None)\n",
    "\n",
    "    # Optimize the model\n",
    "    gpflow.optimizers.Scipy().minimize(model.training_loss, model.trainable_variables)\n",
    "\n",
    "    # Prediction for visualization\n",
    "    X_new = tf.convert_to_tensor(np.arange(num_nodes).reshape(-1, 1), dtype=tf.float64)  # New input features for prediction\n",
    "    mean, variance = model.predict_f(X_new)  # Predict mean and variance\n",
    "    stddev = tf.sqrt(variance)  # Standard deviation\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(X.numpy(), Y.numpy(), 'ro', label='Noisy Samples')  # Sampled data points\n",
    "    plt.plot(X_new.numpy(), mean.numpy(), 'b-', label='Fitted Mean')  # Fitted mean\n",
    "    plt.fill_between(X_new.numpy().flatten(), \n",
    "                     (mean - 1.96 * stddev).numpy().flatten(), \n",
    "                     (mean + 1.96 * stddev).numpy().flatten(), \n",
    "                     color='lightblue', alpha=0.5, label='95% Confidence Interval')  # 95% confidence interval\n",
    "    plt.title(f'Gaussian Process Fit with Graph Diffusion Kernel (beta={beta_sample})')\n",
    "    plt.xlabel('Node Number')\n",
    "    plt.ylabel('Sampled Value')\n",
    "    plt.xticks(range(num_nodes))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"Learned beta:\", model.kernel.beta.numpy())\n",
    "\n",
    "# Create a slider for beta\n",
    "beta_slider = widgets.FloatSlider(value=3.0, min=0.1, max=10.0, step=0.1, description='Beta:')\n",
    "ui = widgets.VBox([beta_slider])\n",
    "\n",
    "# Link the slider to the plotting function\n",
    "out = widgets.interactive_output(plot_results, {'beta_sample': beta_slider})\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the (linear) graph we fit and the fitted GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4463a8f4041c49fa80dffc3f06e232b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=3.0, description='Beta:', max=10.0, min=0.1),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b5ab98c3844fac925fd3e12cd54c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objs as go\n",
    "import networkx as nx\n",
    "\n",
    "# Function to compute the diffusion kernel\n",
    "def diffusion_kernel(adj_matrix, beta):\n",
    "    laplacian = np.diag(np.sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "    return expm(-beta * laplacian)  # Matrix exponential\n",
    "\n",
    "# Parameters\n",
    "num_nodes = 40\n",
    "adjacency_matrix = np.eye(num_nodes, k=1) + np.eye(num_nodes, k=-1)  # Circular adjacency matrix\n",
    "\n",
    "# Generate noisy samples function\n",
    "def generate_noisy_samples(beta_sample):\n",
    "    K = diffusion_kernel(adjacency_matrix, beta_sample)\n",
    "    L = np.linalg.cholesky(K + 1e-6 * np.eye(num_nodes))  # Cholesky decomposition\n",
    "    true_samples = L @ np.random.normal(size=(num_nodes, 1))  # Sample from Gaussian process\n",
    "    noise = 0.1 * np.random.randn(num_nodes, 1)  # Additive noise\n",
    "    Y_noisy = true_samples + noise  # Noisy observations\n",
    "    return Y_noisy\n",
    "\n",
    "# Modified `K` function in GraphDiffusionKernel class\n",
    "class GraphDiffusionKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self, adjacency_matrix, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.adjacency_matrix = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float64)\n",
    "        self.beta = gpflow.Parameter(2.0, transform=gpflow.utilities.positive())  # Learnable hyperparameter\n",
    "\n",
    "    def K(self, X1, X2=None):\n",
    "        if X2 is None:\n",
    "            X2 = X1\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        indices_X1 = tf.cast(tf.reshape(X1, [-1]), dtype=tf.int32)\n",
    "        indices_X2 = tf.cast(tf.reshape(X2, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.gather(kernel_matrix, indices_X1, axis=0), indices_X2, axis=1)\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        indices_X = tf.cast(tf.reshape(X, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.linalg.diag_part(kernel_matrix), indices_X)\n",
    "\n",
    "    def diffusion_kernel(self, adj_matrix, beta):\n",
    "        laplacian = tf.linalg.diag(tf.reduce_sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "        return tf.linalg.expm(-beta * laplacian)\n",
    "\n",
    "# Function to plot the results\n",
    "def plot_results(beta_sample):\n",
    "    clear_output(wait=True)  # Clear previous output\n",
    "    # Generate noisy samples\n",
    "    Y_noisy = generate_noisy_samples(beta_sample)\n",
    "\n",
    "    # Convert noisy data to TensorFlow tensor\n",
    "    X = tf.convert_to_tensor(np.arange(num_nodes, dtype=np.float64).reshape(-1, 1))  # Input features (nodes)\n",
    "    Y = tf.convert_to_tensor(Y_noisy, dtype=tf.float64)  # Noisy sampled data\n",
    "\n",
    "    # Create an instance of the kernel\n",
    "    graph_kernel = GraphDiffusionKernel(adjacency_matrix)\n",
    "\n",
    "    # GPflow model\n",
    "    model = gpflow.models.GPR(data=(X, Y), kernel=graph_kernel, mean_function=None)\n",
    "\n",
    "    # Optimize the model\n",
    "    gpflow.optimizers.Scipy().minimize(model.training_loss, model.trainable_variables)\n",
    "\n",
    "    # Prediction for visualization\n",
    "    X_new = tf.convert_to_tensor(np.arange(num_nodes).reshape(-1, 1), dtype=tf.float64)  # New input features for prediction\n",
    "    mean, variance = model.predict_f(X_new)  # Predict mean and variance\n",
    "    stddev = tf.sqrt(variance)  # Standard deviation\n",
    "\n",
    "    # Plotting the Gaussian Process results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # GP plot on the left\n",
    "    ax[0].plot(X.numpy(), Y.numpy(), 'ro', label='Noisy Samples')\n",
    "    ax[0].plot(X_new.numpy(), mean.numpy(), 'b-', label='Fitted Mean')\n",
    "    ax[0].fill_between(X_new.numpy().flatten(),\n",
    "                       (mean - 1.96 * stddev).numpy().flatten(),\n",
    "                       (mean + 1.96 * stddev).numpy().flatten(),\n",
    "                       color='lightblue', alpha=0.5, label='95% Confidence Interval')\n",
    "    ax[0].set_title(f'Gaussian Process Fit with Graph Diffusion Kernel (beta={beta_sample})')\n",
    "    ax[0].set_xlabel('Node Number')\n",
    "    ax[0].set_ylabel('Sampled Value')\n",
    "    ax[0].grid()\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # Plot the network graph using NetworkX and Plotly\n",
    "    plot_network_graph(adjacency_matrix, ax[1])\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Learned beta:\", model.kernel.beta.numpy())\n",
    "\n",
    "# Function to plot the network graph in Matplotlib\n",
    "def plot_network_graph(adjacency_matrix, ax):\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    G = nx.from_numpy_array(adjacency_matrix)\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax, node_size=300, node_color='red')\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, edge_color='blue')\n",
    "    \n",
    "    ax.set_title(\"Network Graph Representation of Adjacency Matrix\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Create a slider for beta\n",
    "beta_slider = widgets.FloatSlider(value=3.0, min=0.1, max=10.0, step=0.1, description='Beta:')\n",
    "ui = widgets.VBox([beta_slider])\n",
    "\n",
    "# Link the slider to the plotting function\n",
    "out = widgets.interactive_output(plot_results, {'beta_sample': beta_slider})\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fb4972ce5d4da19a95333ee30db093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=3.0, description='Beta:', max=10.0, min=0.1),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc14589e4c934358ae3f6bb39a1f4495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import networkx as nx\n",
    "\n",
    "# Function to compute the diffusion kernel\n",
    "def diffusion_kernel(adj_matrix, beta):\n",
    "    laplacian = np.diag(np.sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "    return expm(-beta * laplacian)  # Matrix exponential\n",
    "\n",
    "# Parameters\n",
    "num_nodes = 100\n",
    "# Generate an undirected random graph\n",
    "probability = 0.03  # Probability of edge creation\n",
    "G = nx.erdos_renyi_graph(num_nodes, probability, directed=False)  # Ensure the graph is undirected\n",
    "adjacency_matrix = nx.to_numpy_array(G)  # Convert to adjacency matrix\n",
    "\n",
    "# Generate noisy samples function\n",
    "def generate_noisy_samples(beta_sample):\n",
    "    K = diffusion_kernel(adjacency_matrix, beta_sample)\n",
    "    L = np.linalg.cholesky(K + 1e-6 * np.eye(num_nodes))  # Cholesky decomposition\n",
    "    true_samples = L @ np.random.normal(size=(num_nodes, 1))  # Sample from Gaussian process\n",
    "    noise = 0.1 * np.random.randn(num_nodes, 1)  # Additive noise\n",
    "    Y_noisy = true_samples + noise  # Noisy observations\n",
    "    return Y_noisy\n",
    "\n",
    "# Modified `K` function in GraphDiffusionKernel class\n",
    "class GraphDiffusionKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self, adjacency_matrix, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.adjacency_matrix = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float64)\n",
    "        self.beta = gpflow.Parameter(2.0, transform=gpflow.utilities.positive())  # Learnable hyperparameter\n",
    "\n",
    "    def K(self, X1, X2=None):\n",
    "        if X2 is None:\n",
    "            X2 = X1\n",
    "        # Compute the full diffusion kernel\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        indices_X1 = tf.cast(tf.reshape(X1, [-1]), dtype=tf.int32)\n",
    "        indices_X2 = tf.cast(tf.reshape(X2, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.gather(kernel_matrix, indices_X1, axis=0), indices_X2, axis=1)\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        kernel_matrix = self.diffusion_kernel(self.adjacency_matrix, self.beta)\n",
    "        indices_X = tf.cast(tf.reshape(X, [-1]), dtype=tf.int32)\n",
    "        return tf.gather(tf.linalg.diag_part(kernel_matrix), indices_X)\n",
    "\n",
    "    def diffusion_kernel(self, adj_matrix, beta):\n",
    "        laplacian = tf.linalg.diag(tf.reduce_sum(adj_matrix, axis=1)) - adj_matrix  # Graph Laplacian\n",
    "        return tf.linalg.expm(-beta * laplacian)\n",
    "\n",
    "# Function to plot the results\n",
    "def plot_results(beta_sample):\n",
    "    clear_output(wait=True)  # Clear previous output\n",
    "    # Generate noisy samples\n",
    "    Y_noisy = generate_noisy_samples(beta_sample)\n",
    "\n",
    "    # Convert noisy data to TensorFlow tensor\n",
    "    X = tf.convert_to_tensor(np.arange(num_nodes, dtype=np.float64).reshape(-1, 1))  # Input features (nodes)\n",
    "    Y = tf.convert_to_tensor(Y_noisy, dtype=tf.float64)  # Noisy sampled data\n",
    "\n",
    "    # Create an instance of the kernel\n",
    "    graph_kernel = GraphDiffusionKernel(adjacency_matrix)\n",
    "\n",
    "    # GPflow model\n",
    "    model = gpflow.models.GPR(data=(X, Y), kernel=graph_kernel, mean_function=None)\n",
    "\n",
    "    # Optimize the model\n",
    "    gpflow.optimizers.Scipy().minimize(model.training_loss, model.trainable_variables)\n",
    "\n",
    "    # Prediction for visualization\n",
    "    X_new = tf.convert_to_tensor(np.arange(num_nodes).reshape(-1, 1), dtype=tf.float64)  # New input features for prediction\n",
    "    mean, variance = model.predict_f(X_new)  # Predict mean and variance\n",
    "    stddev = tf.sqrt(variance)  # Standard deviation\n",
    "\n",
    "    # Create side-by-side plots for GP and network graph\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Gaussian Process plot on the left\n",
    "    ax[0].plot(X.numpy(), Y.numpy(), 'ro', label='Noisy Samples')\n",
    "    ax[0].plot(X_new.numpy(), mean.numpy(), 'b-', label='Fitted Mean')\n",
    "    ax[0].fill_between(X_new.numpy().flatten(),\n",
    "                       (mean - 1.96 * stddev).numpy().flatten(),\n",
    "                       (mean + 1.96 * stddev).numpy().flatten(),\n",
    "                       color='lightblue', alpha=0.5, label='95% Confidence Interval')\n",
    "    ax[0].set_title(f'Gaussian Process Fit with Graph Diffusion Kernel (beta={beta_sample})')\n",
    "    ax[0].set_xlabel('Node Number')\n",
    "    ax[0].set_ylabel('Sampled Value')\n",
    "    ax[0].grid()\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # Network graph plot on the right\n",
    "    plot_network_graph(adjacency_matrix, ax[1])\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Learned beta:\", model.kernel.beta.numpy())\n",
    "\n",
    "# Function to plot the network graph in Matplotlib\n",
    "def plot_network_graph(adjacency_matrix, ax):\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    G = nx.from_numpy_array(adjacency_matrix)\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax, node_size=300, node_color='red')\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, edge_color='blue')\n",
    "    \n",
    "    ax.set_title(\"Network Graph Representation of Adjacency Matrix\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Create a slider for beta\n",
    "beta_slider = widgets.FloatSlider(value=3.0, min=0.1, max=10.0, step=0.1, description='Beta:')\n",
    "ui = widgets.VBox([beta_slider])\n",
    "\n",
    "# Link the slider to the plotting function\n",
    "out = widgets.interactive_output(plot_results, {'beta_sample': beta_slider})\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (754214315.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    G py\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# G py\n",
    "\n",
    "# GPflow\n",
    "\n",
    "# GP Jax\n",
    "\n",
    "\n",
    "# constained optimization - positive values - minimize() still works\n",
    "\n",
    "\n",
    "\n",
    "# f (modulation function) exist  - postitive definite kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
